{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866cd890-0032-486e-978b-01bd1b95a948",
   "metadata": {},
   "source": [
    "### Utility Methods\n",
    "This method is used to bridge the difference in the port collection frequency between application QoE evaluation platform and WiFi metrics collection platform. Since application metrics are collected at twice more frequently i.e. every quarter of a second, this method rounds up the time stamp half a second duration and then we can get average values of MOS score, TI & SI values by grouping the QoE metrics data by the rounded timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "875f31ae-25bd-4f27-b4a7-aec79341615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_round(value):\n",
    "    # Round up to one decimal point\n",
    "    rounded_value = np.ceil(value * 10) / 10\n",
    "    # Check if first decimal is less than 5, set it to 0\n",
    "    if (rounded_value * 10) % 10 <= 5:\n",
    "        return np.floor(rounded_value)\n",
    "    else:\n",
    "        return np.floor(rounded_value) + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca648f-bb95-4cc5-b8bd-e4d9f03c43f8",
   "metadata": {},
   "source": [
    "Following two methods parse \"port_metrics.csv\" and \"vap_metrics.csv\" file respectively and returns a data frame with interested KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37e212e-35ab-4de0-88cf-c57800e03cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_port_metrics(file):\n",
    "    datagram = pd.read_csv(file)\n",
    "    cols = ['activity', 'noise', 'rx-rate', 'tx-rate', 'beacon', 'bps rx',\n",
    "            'bps rx ll', 'bps tx', 'bps tx ll', 'channel', 'collisions', 'connections', 'pps rx', 'pps tx', 'qlen', 'retry failed', 'rx crc',\n",
    "        'rx drop', 'rx errors', 'rx fifo', 'rx frame', 'rx length', 'rx miss', 'rx pkts', 'signal', 'tx pkts',\n",
    "        'rx over', 'tx abort', 'tx crr', 'tx errors', 'tx fifo', 'tx hb',\n",
    "        'tx wind', 'tx-failed %', 'wifi retries', 'timestamp']\n",
    "    df = datagram.loc[:, cols]\n",
    "    df['db'] = df['noise'].str.extract('(^[-+]?\\d+)').astype(float)\n",
    "    df['sig'] = df['signal'].str.extract('(^[-+]?\\d+)').astype(float)\n",
    "    df['rxrate'] = df['rx-rate'].str.extract('(^[-+]?\\d+)').astype(float)\n",
    "    df['txrate'] = df['tx-rate'].str.extract('(^[-+]?\\d+)').astype(float)\n",
    "    df = df.drop(['noise', 'rx-rate', 'tx-rate', 'signal'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45517bc1-a6f2-497b-86cf-55644f2e8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vap_metrics(file):\n",
    "    data = pd.read_csv(file)\n",
    "    col_map = {'idle': 'sta_idle', 'signal': 'sta_signal', 'signal avg': 'sta_signal_avg',\n",
    "               'tx retries': 'sta_tx_retries', 'tx-failed': 'sta_tx_failed'}\n",
    "    cols = ['idle', 'rx rate', 'signal', 'signal avg', 'tx rate', 'tx retries', 'tx-failed', 'tx pkts', 'rx pkts', 'station bssid', 'timestamp']\n",
    "    df = data.loc[:, cols]\n",
    "    df.rename(columns = col_map, inplace = True)\n",
    "    df['sta_rx_rate'] = df['rx rate'].str.extract('(^[-+]?\\d+)').astype(float)\n",
    "    df['sta_tx_rate'] = df['tx rate'].str.extract('(^[-+]?\\d+)').astype(float)\n",
    "    df['sta_tx_pkts'] = df['tx pkts']\n",
    "    df['sta_rx_pkts'] = df['rx pkts']\n",
    "    df['sta_bssid'] = df['station bssid']\n",
    "    df = df.drop(['rx rate', 'tx rate', 'tx pkts', 'rx pkts', 'station bssid'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ea9a2-2331-4b15-b27a-289d5e608586",
   "metadata": {},
   "source": [
    "This method merges QoE metrics with WiFi metrics. Each Application QOE metrics data set (row) is duplicated as many virtual STAs used in a particular experiment instance and then merged with already merged Port and VAP metrics data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a947d309-a9de-4fcf-81bd-9e1e73233037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_qoe_df(port_df, qoe_df):\n",
    "    ts_count = port_df.groupby('timestamp')['stas'].count().shape[0]\n",
    "    if all(col in qoe_df.columns for col in ['MOS', 'SI', 'TI']):\n",
    "        grouped_qoe = qoe_df.groupby('ts')[['MOS', 'SI', 'TI']].mean().round(1).reset_index()\n",
    "        #grouped_qoe.rename(columns = {'ts': 'timestamp'}, inplace = True)\n",
    "        #print(grouped_qoe.shape, ts_count)\n",
    "        if grouped_qoe.shape[0] > ts_count:\n",
    "            merge_qoe = grouped_qoe.iloc[: int(ts_count - grouped_qoe.shape[0])]\n",
    "        elif grouped_qoe.shape[0] < ts_count:\n",
    "            return None\n",
    "        else:\n",
    "            merge_qoe = grouped_qoe.copy()\n",
    "\n",
    "        # Empty list to store the repeated rows\n",
    "        repeated_rows = []\n",
    "        # Iterate through the Series and df_left\n",
    "        for idx, value in enumerate(port_df.groupby('timestamp')['stas'].count()):\n",
    "            # Repeat the row value times\n",
    "            repeated_row = pd.DataFrame(np.repeat(merge_qoe.iloc[[idx]], value, axis = 0), columns = merge_qoe.columns)\n",
    "            repeated_rows.append(repeated_row)\n",
    "\n",
    "        # Concatenate all the repeated rows\n",
    "        qoe_repeated = pd.concat(repeated_rows, ignore_index=True)\n",
    "        #print(f\"# QoE concated shape {qoe_repeated.shape} #\")\n",
    "        # Merge the repeated left DataFrame with the right DataFrame\n",
    "        df_merged = pd.merge(port_df, qoe_repeated, left_index=True, right_index=True)\n",
    "        #print(f\"# Merged QoE DF shape {df_merged.shape} #\")\n",
    "\n",
    "    # vSTAs with RX rate less than or equal to 6.0 are dummy vSTAs, so drop those rows.\n",
    "    return df_merged.query('sta_rx_rate > 6.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60c721-6926-420b-acde-e7b5ba92d06e",
   "metadata": {},
   "source": [
    "### Recursive WiFi metrics, QoE metrics merging utility function\n",
    "This method is the root method that walks through the data directory and merges Wifi port metrics with virtual STA metrics as well as application QoE metrics. Merged data frames are returned as a map between the root path (experiment instance) and the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31ed7c39-3119-4115-aecf-be45d2fde23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_port_vap_metrics(base):\n",
    "    dataframes = dict()\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        pf = 'port_metrics.csv' in files\n",
    "        vf = 'vap_metrics.csv' in files\n",
    "        qf = 'Qoe.xlsx' in files\n",
    "\n",
    "        # If CSV files exist in the current directory\n",
    "        row_repeat = 11\n",
    "        if pf and vf and qf:\n",
    "            pm_df = parse_port_metrics(os.path.join(root, 'port_metrics.csv')).sort_values(by = 'timestamp', ascending = True)\n",
    "            vm_df = parse_vap_metrics(os.path.join(root, 'vap_metrics.csv')).sort_values(by = 'timestamp', ascending = True)\n",
    "\n",
    "            splits = root.split('/')\n",
    "            vm_df['direction'] = splits[3]\n",
    "            vm_df['distance'] = splits[5]\n",
    "            vm_df['sta_bw'] = int(re.search(r'^\\d+', splits[6]).group()) if re.search(r'^\\d+', splits[6]) is not None else 0\n",
    "            vm_df['stas'] = int(re.search(r'^\\d+', splits[7]).group()) if re.search(r'^\\d+', splits[7]) is not None else 0\n",
    "\n",
    "            repeated_rows = []\n",
    "            for idx, value in enumerate(vm_df.groupby('timestamp')['sta_bssid'].count()):\n",
    "                repeated_row = pd.DataFrame(np.repeat(pm_df.iloc[[idx]], value, axis = 0), columns = pm_df.columns)\n",
    "                repeated_rows.append(repeated_row)\n",
    "\n",
    "            pm_r = pd.concat(repeated_rows, ignore_index=True).drop('timestamp', axis = 1)\n",
    "            #print(f\"## PM DF concated shape: {pm_r.shape} ##\")\n",
    "            \n",
    "            merged_df = pd.merge(pm_r, vm_df, left_index=True, right_index=True)\n",
    "            #print(f\"## Merged DF shape {merged_df.shape} ##\")\n",
    "            sorted_df = merged_df.sort_values(by='timestamp', ascending = True)\n",
    "\n",
    "            qoe_xlsx = pd.read_excel(os.path.join(root, 'Qoe.xlsx'), sheet_name = 'Raw Data 1')\n",
    "            qoe_n = qoe_xlsx.loc[:, ['TimeStamp', 'MOS', 'SI', 'TI']]\n",
    "            qoe_n['ts'] = qoe_n['TimeStamp'].apply(custom_round)\n",
    "\n",
    "            qoe_n['MOS_R'] = qoe_n['MOS'].round(1)\n",
    "            qoe_n.drop(['TimeStamp', 'MOS'], axis = 1, inplace = True)\n",
    "            qoe_n.rename(columns = {'MOS_R': 'MOS'}, inplace = True)\n",
    "\n",
    "            if qoe_n.groupby('ts')['MOS'].count()[0] >= 120:\n",
    "                qoe = qoe_n.query('ts >= 1 and ts <= 62')\n",
    "            else:\n",
    "                qoe = qoe_n.copy()\n",
    "\n",
    "            df =  merge_qoe_df(sorted_df, qoe)\n",
    "            if df is not None:\n",
    "                dataframes[root] = df\n",
    "\n",
    "    return dataframes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
